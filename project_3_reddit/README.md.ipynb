{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement \n",
    "\n",
    "Scrape posts from 2 Sub-Reddit forums and develop a Natural Language Processing model to accurately classify posts from each of these forums. \n",
    "\n",
    "\n",
    "# Executive Summary\n",
    "\n",
    "I scraped posts from the \"World news\" and \"Today I Learned\" Sub-reddit forums. \n",
    "\n",
    "Total posts scraped were:\n",
    "- 999 posts from 'TIL' forum\n",
    "- 693 posts from 'World News' forum \n",
    "\n",
    "**Dataframe: all_df**\n",
    "\n",
    "|Name|Type|Description|\n",
    "|---|---|---|\n",
    "|**subreddit**|*int64*|Binary values of '0' for TIL posts and '1' for World news| \n",
    "|**title**|*str*|Original uncleaned individual posts from the subreddit forums|\n",
    "|**clean_posts**|*str*|cleaned individual posts from the subreddit forums|\n",
    "|**clean_posts2**|*str*|cleaned individual posts from the subreddit forums without the 'til' term|\n",
    "\n",
    "\n",
    "# Model Fitting and Results\n",
    "\n",
    "We fitted a baseline model scoring using a few variations of the Naive Bayes Classification model and compared it against the scores using alternative models like Logisitic Regression and Decision Tree Classifer. \n",
    "\n",
    "**Baseline Model Scoring**\n",
    "\n",
    "**Round 1 (Raw model + dataset)**\n",
    "\n",
    "For the Naive Bayes model, I initially fitted and scored the model against the original training data set (1269 posts, 5584 features) and also scored it against the test set (423 posts, 5584 features). \n",
    "\n",
    "\n",
    "The data was vectorised using both Count Vectorizer and TFIDF Vectorizer before being fitted on the model using a standard Bayesian classifer model with the following combinations:\n",
    "\n",
    "\n",
    "- Cvec train/test score (Bernoulli): 1.0 / 0.995\n",
    "- Cvec train/test score(Multinomial): 0.999 / 0.957\n",
    "- Tvec train/test score(Gaussian): 1.0 / 0.898\n",
    "\n",
    "**Round 2 (Raw model + removed 'til' term)**\n",
    "\n",
    "I took a closer look at the word frequencies and figured that 'til' was appearing too frequently in the 'TIL' sub-reddit posts - ran a 2nd fitting after removing the term 'til'.\n",
    "\n",
    "Scores without 'til' term\n",
    "- Cvec train score (Bernoulli): 0.988 / 0.926\n",
    "- Cvec train score(Multinomial): 0.993 / 0.919\n",
    "- Tvec train score(Gaussian): 1.0 / 0.891 \n",
    "\n",
    "The model scores still seem slightly overfitted for CVEC + Bernoulli but in slightly better shape for the CVEC Multinomial combination.\n",
    "\n",
    "**Round 3 (Hyper-parameter tuning + removed 'til' term)** \n",
    "\n",
    "\n",
    "Adapted a custom class function to take in multiple models and their respective parameters and pass in through Gridsearch CV.\n",
    "\n",
    "The main hyperparameters that i was tuning for included:\n",
    "- max features\n",
    "- minimum document frequency\n",
    "- maximum document frequency \n",
    "- ngram range \n",
    "\n",
    "The Model mixes (not too unlike above were):\n",
    "- CVEC + Bernoulli / Multinomial Bayes\n",
    "- TVEC + Bernoulli / Multinomial Bayes\n",
    "\n",
    "Ran them through the function to optimise for different metrics:\n",
    "- Accuracy: TVEC + Multinomial 0.897 (0.9 max df, 750 max features, 3 min df, n gram (1,1)) \n",
    "- Balanced Accuracy: CVEC + Bernoulli 0.889 (0.9 max df, 750 max features, 3 min df, n gram (1,1))\n",
    "- F1 score: TVEC + Multinomial 0.870 (0.9 max df, 750 max features, 3 min df, n gram (1,1))\n",
    "- Specificity: TVEC + Multinomial 0.908 (0.95 max df, 750 max features, 3 min df, n gram (1,1))\n",
    "\n",
    "Overall it seemed like the plain models still worked better than the hyper-tuned ones!\n",
    "\n",
    "\n",
    "**Fitting against other models**\n",
    "\n",
    "**CountVect + Log Reg**\n",
    "\n",
    "- without tuning (train score: 1, test score: 0.919)\n",
    "- with tuning (train score: 0.916, test score: 0.888)\n",
    "- Sensitivity: 0.8382\n",
    "- Specificity: 0.948\n",
    "- Precision: 0.9177\n",
    "- Accuracy: 0.9031\n",
    "- F1 Score: 0.8761\n",
    "\n",
    "**TFIDFVect + Log Reg** \n",
    "\n",
    "- without tuning (train score: 0.961, test score: 0.865)\n",
    "- with tuning (train score: 0.899, test score: 0.867)\n",
    "- Sensitivity: 0.815\n",
    "- Specificity: 0.976\n",
    "- Precision: 0.9592\n",
    "- Accuracy: 0.9102\n",
    "- F1 Score: 0.8812\n",
    "\n",
    "**Decision Tree**\n",
    "- Grid search best train score: 0.849\n",
    "- Grid search best test score: 0.804\n",
    "\n",
    "\n",
    "**Verdict** \n",
    "\n",
    "- Untuned Naive Bayes Model (countvect + Multinomial) tied with untuned Countvect + log reg for the higest accuracy score \n",
    "- TFIDF + Log reg had the highest F1 score at 0.88 \n",
    "\n",
    "It was curious that the untuned models consistently performed better than their tuned counterparts - perhaps this was a result of the lack of proper tuning? (maybe i should have explored a wider range of parameters). \n",
    "\n",
    "I am also unsure why amongst the tuned models, the optimal hyperparameters selected were unigram only since intuitively, bigrams would have made for better contextual classification. \n",
    "\n",
    "In terms of usage, I am unsure that the model can serve as a good classifier of updated future reddit posts as the list of words used in both TIL and world news would probably be constantly changing? it would probably have to be trained over a larger dataset over time.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
